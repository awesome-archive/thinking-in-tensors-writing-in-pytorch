{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To do\n",
    "\n",
    "* text from https://www.reddit.com/r/MachineLearning/comments/ecazk2/d_gpu_benchmarks_for_deep_learning_tasks/\n",
    "* some comments there https://www.reddit.com/r/MachineLearning/comments/c6jxog/p_ai_benchmark_a_new_standard_for_ml_performance/\n",
    "* also numpy\n",
    "* some plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from timeit import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10.1'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.version.cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GeForce RTX 2080 with Max-Q Design'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_CudaDeviceProperties(name='GeForce RTX 2080 with Max-Q Design', major=7, minor=5, total_memory=8192MB, multi_processor_count=46)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_properties('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09138809999998898"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeit(func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.randn((10000, 10000))\n",
    "v = torch.randn((10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#timeit(lambda: A.matmul(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.7 ms ± 136 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "A.matmul(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = A.to(device)\n",
    "v = v.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.24 ms ± 9.69 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "A.matmul(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.randn((1000, 1000))\n",
    "B = torch.randn((1000, 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.17 ms ± 96.4 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "A.matmul(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = A.to(device)\n",
    "B = B.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "456 µs ± 5.98 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "A.matmul(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.randn((10000, 10000))\n",
    "B = torch.randn((10000, 10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.74 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-1.9520e+01,  6.9182e+01,  1.1564e+02,  ...,  1.2619e+02,\n",
       "         -6.4699e+01,  1.6668e+02],\n",
       "        [-1.2492e+02, -1.0849e+02, -2.6037e+01,  ..., -7.8305e+01,\n",
       "         -1.9603e+02,  6.1230e+01],\n",
       "        [-1.0486e+00, -6.5757e+01,  2.1775e+02,  ...,  9.2899e+01,\n",
       "         -3.7656e+01, -1.0037e+02],\n",
       "        ...,\n",
       "        [-1.5888e+02,  7.1087e+01,  4.1497e+01,  ..., -5.4155e+01,\n",
       "         -9.1897e+01, -5.1101e+01],\n",
       "        [ 2.7407e+01,  8.0948e+01,  2.1446e+02,  ..., -3.9251e-02,\n",
       "          2.5917e+02,  1.5489e+01],\n",
       "        [ 6.1963e+01,  2.8205e+01,  1.2452e+02,  ..., -2.2053e+01,\n",
       "          1.3920e+02, -2.7770e+01]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "A.matmul(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timeit says:\n",
    "# 5.7 s ± 183 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = A.to(device)\n",
    "B = B.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 416 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-1.9520e+01,  6.9182e+01,  1.1564e+02,  ...,  1.2619e+02,\n",
       "         -6.4699e+01,  1.6668e+02],\n",
       "        [-1.2492e+02, -1.0849e+02, -2.6037e+01,  ..., -7.8305e+01,\n",
       "         -1.9603e+02,  6.1230e+01],\n",
       "        [-1.0487e+00, -6.5757e+01,  2.1775e+02,  ...,  9.2899e+01,\n",
       "         -3.7656e+01, -1.0037e+02],\n",
       "        ...,\n",
       "        [-1.5888e+02,  7.1087e+01,  4.1497e+01,  ..., -5.4155e+01,\n",
       "         -9.1897e+01, -5.1101e+01],\n",
       "        [ 2.7407e+01,  8.0948e+01,  2.1446e+02,  ..., -3.9189e-02,\n",
       "          2.5917e+02,  1.5489e+01],\n",
       "        [ 6.1963e+01,  2.8205e+01,  1.2452e+02,  ..., -2.2053e+01,\n",
       "          1.3920e+02, -2.7770e+01]], device='cuda:0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "A.matmul(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And Float16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = A.cpu().half()\n",
    "B = B.cpu().half()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.3301,  1.4033, -0.1700,  ..., -0.4141,  1.4805,  0.3557],\n",
       "        [ 0.0626,  1.5762, -0.7759,  ...,  0.9121,  0.8638,  0.1989],\n",
       "        [ 1.0459,  0.0194,  0.1581,  ...,  1.5264,  1.1943, -1.3916],\n",
       "        ...,\n",
       "        [-0.3701,  0.7959, -0.1727,  ..., -0.9199,  0.1326, -0.6104],\n",
       "        [-0.0676, -0.4153,  2.1602,  ..., -0.9980, -0.1550,  0.7407],\n",
       "        [-1.8232, -0.6748,  1.4727,  ...,  0.6724,  0.3904,  0.4854]],\n",
       "       dtype=torch.float16)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "_th_mm not supported on CPUType for Half",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: _th_mm not supported on CPUType for Half"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "A.matmul(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = A.to(device)\n",
    "B = B.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9.01 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-1.9500e+01,  6.9188e+01,  1.1562e+02,  ...,  1.2625e+02,\n",
       "         -6.4688e+01,  1.6675e+02],\n",
       "        [-1.2488e+02, -1.0850e+02, -2.6016e+01,  ..., -7.8312e+01,\n",
       "         -1.9600e+02,  6.1250e+01],\n",
       "        [-1.0352e+00, -6.5812e+01,  2.1775e+02,  ...,  9.2875e+01,\n",
       "         -3.7656e+01, -1.0038e+02],\n",
       "        ...,\n",
       "        [-1.5888e+02,  7.1125e+01,  4.1500e+01,  ..., -5.4094e+01,\n",
       "         -9.1875e+01, -5.1125e+01],\n",
       "        [ 2.7391e+01,  8.0938e+01,  2.1450e+02,  ...,  7.1289e-02,\n",
       "          2.5925e+02,  1.5484e+01],\n",
       "        [ 6.1969e+01,  2.8188e+01,  1.2456e+02,  ..., -2.2047e+01,\n",
       "          1.3925e+02, -2.7750e+01]], device='cuda:0', dtype=torch.float16)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "A.matmul(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p37-pytorch",
   "language": "python",
   "name": "p37-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
