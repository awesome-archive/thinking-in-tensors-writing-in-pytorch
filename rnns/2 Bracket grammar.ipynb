{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thinking in tensors in PyTorch\n",
    "\n",
    "Hands-on training  by [Piotr Migda≈Ç](https://p.migdal.pl) (2019). \n",
    "\n",
    "Version for [AI & NLP Workshop Day](https://nlpday.pl/), 31 May 2019, Warsaw, Poland: **Understanding LSTM and GRU networks in PyTorch**.\n",
    "\n",
    "\n",
    "## NLP & AI: 2. Bracket grammar\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/stared/thinking-in-tensors-writing-in-pytorch/blob/master/extra/2%20Bracket%20grammar.ipynb)\n",
    "\n",
    "To show grammar-detection (as opposed to just pattern-detection), we will try to teach a neural network to check if sequence of brackets is correct. \n",
    "\n",
    "While it is an artificial dataset, many other problems have similar structure, e.g.:\n",
    "\n",
    "* sentences starting with a capital letter and ending with `.`, `?` or `!`,\n",
    "* HTML and XML tags,\n",
    "* various codes,\n",
    "* etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_string = \"()()\" + (32 - 4) * \" \"\n",
    "base_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_string(s):\n",
    "    indices = np.arange(len(s), dtype='uint8')\n",
    "    np.random.shuffle(indices)\n",
    "    return \"\".join(base_string[i] for i in indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_string(base_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# of course, it is possible to check correctness manually\n",
    "# we use it to generate data\n",
    "def is_correct(seq):\n",
    "    open_brackets = 0\n",
    "    val = {\"(\": 1, \" \": 0, \")\": -1}\n",
    "    for c in seq:\n",
    "        open_brackets += val[c]\n",
    "        if open_brackets < 0:\n",
    "            return False\n",
    "    return open_brackets == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_correct(\"()()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_correct(\"()(\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_correct(\"())(\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating the dataset\n",
    "\n",
    "char2id = {\" \": 0, \"(\": 1, \")\": 2}\n",
    "\n",
    "def generate_pairs(size, random_state=42):\n",
    "    np.random.seed(random_state)\n",
    "    X = np.zeros((size, 3, len(base_string)))\n",
    "    Y = np.zeros((size), dtype='float32')\n",
    "    for i in range(size):\n",
    "        s = shuffle_string(base_string)\n",
    "        Y[i] = float(is_correct(s))\n",
    "        for j, c in enumerate(s):\n",
    "            X[i, char2id[c], j] = 1.\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = generate_pairs(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the fraction of correct strings?\n",
    "Y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before we start...\n",
    "\n",
    "\n",
    "We will create a few neural networks for detecting if brackets are properly matched:\n",
    "\n",
    "* logistic regression\n",
    "* convolutional neural network\n",
    "* recurrent neural network (LSTM or GRU)\n",
    "\n",
    "Which of these networks perform the best? Why?\n",
    "Before we start, let's think:\n",
    "\n",
    "* What is the baseline performance (accuracy)?\n",
    "* What is the accuracy of the logistic regression model?\n",
    "* Do you expect to perform much better than guessing the most common class all the time?\n",
    "\n",
    "CNNs and RNNs will require some tweaking with the number of parameters.\n",
    "\n",
    "Remember to adjust the optimizer and the number of epochs:\n",
    "\n",
    "* learns to slowly -> more epochs or a higher learning rate (or change your optimizer),\n",
    "* does not learn or scores fluctuate too much -> reduce the learning rate (or change your optimizer).\n",
    "\n",
    "Also, let's install:\n",
    "\n",
    "* `pip install livelossplot` - [Live training loss plot in Jupyter Notebook for Keras, PyTorch and others](https://github.com/stared/livelossplot/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if run from colab\n",
    "!pip install -q livelossplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from livelossplot import PlotLosses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(TensorDataset(torch.from_numpy(X_train).float(),\n",
    "                                       torch.from_numpy(Y_train).long()),\n",
    "                         batch_size=16, shuffle=True)\n",
    "testloader = DataLoader(TensorDataset(torch.from_numpy(X_test).float(),\n",
    "                                      torch.from_numpy(Y_test).long()),\n",
    "                         batch_size=16, shuffle=False)\n",
    "\n",
    "dataloaders = {\n",
    "    \"train\": trainloader,\n",
    "    \"validation\": testloader\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train on cuda if available\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def train_model(model, criterion, optimizer, num_epochs=10):\n",
    "    liveloss = PlotLosses()\n",
    "    model = model.to(device)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        logs = {}\n",
    "        for phase in ['train', 'validation']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                if phase == 'train':\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                running_loss += loss.detach() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.float() / len(dataloaders[phase].dataset)\n",
    "            \n",
    "            prefix = ''\n",
    "            if phase == 'validation':\n",
    "                prefix = 'val_'\n",
    "\n",
    "            logs[prefix + 'log loss'] = epoch_loss.item()\n",
    "            logs[prefix + 'accuracy'] = epoch_acc.item()\n",
    "        \n",
    "        liveloss.update(logs)\n",
    "        liveloss.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(32 * 3, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc(x.view(x.size(0), -1))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convolutional(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.convs = nn.Sequential(\n",
    "            self._conv_block(3, channels),\n",
    "            self._conv_block(channels, channels)\n",
    "        )\n",
    "        \n",
    "        output_length = 32 // 2**len(self.convs)\n",
    "        self.fc = nn.Linear(output_length * channels, 2)\n",
    "    \n",
    "    def _conv_block(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv1d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.convs(x)\n",
    "        x = x.view(x.size(0), -1)  # flatten\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentLSTM(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size=3, hidden_size=hidden_size)\n",
    "        # note: input size is the numer of channels/embedding dim, NOT length\n",
    "        self.fc = nn.Linear(hidden_size, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(2, 0, 1)  # BCL -> LBC\n",
    "        output, (hidden, cell) = self.lstm(x)\n",
    "        res = self.fc(cell).squeeze(0)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentGRU(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(input_size=3, hidden_size=hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(2, 0, 1)  # BCL -> LBC \n",
    "        output, hidden = self.gru(x)\n",
    "        res = self.fc(hidden).squeeze(0)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the same criterion for everything!\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Linear()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "train_model(model, criterion, optimizer, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Convolutional(channels=8)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "train_model(model, criterion, optimizer, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RecurrentLSTM(hidden_size=8)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
    "train_model(model, criterion, optimizer, num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RecurrentGRU(hidden_size=8)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
    "train_model(model, criterion, optimizer, num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_str(model, s):\n",
    "    X = torch.zeros((1, 3, len(s)))\n",
    "    for j, c in enumerate(s):\n",
    "        X[0, char2id[c], j] = 1.\n",
    "    return model(X).softmax(dim=1)[0, 1].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_str(model, \"      (   (           )       ) \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_str(model, \"      (   )           (       ) \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_str(model, \"      )   )           (       ( \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_str(model, \"     ( ) ( ) \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
